from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, func, case, text, delete, and_, desc
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, AsyncGenerator, Tuple
import logging
import asyncio
from sqlalchemy.exc import SQLAlchemyError
from ...models import (
    FeatureUsage,
    FeatureUsageMetrics,
    User,
    DetailedGenerationMetrics
)
from ...core.constants import ContentType, UserRole
from ...services.optimization import QueryOptimizer, BatchProcessor
from ...core.cache import CacheService
from ...core.database import async_session

logger = logging.getLogger(__name__)


class FeatureUsageService:
    """Service for tracking and analyzing feature usage with optimization"""

    # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–æ–Ω—Å—Ç–∞–Ω—Ç—ã
    DEFAULT_BATCH_SIZE = 200  # –£–≤–µ–ª–∏—á–µ–Ω–Ω—ã–π —Ä–∞–∑–º–µ—Ä –ø–∞–∫–µ—Ç–∞ –¥–ª—è —Å–Ω–∏–∂–µ–Ω–∏—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –æ–ø–µ—Ä–∞—Ü–∏–π
    DEFAULT_CACHE_TTL = 3600  # 1 —á–∞—Å
    DEFAULT_CLEANUP_DAYS = 90
    DASHBOARD_CACHE_TTL = 600  # 10 –º–∏–Ω—É—Ç –¥–ª—è –¥–∞—à–±–æ—Ä–¥–∞
    ANALYTICS_CACHE_TTL = 1800  # 30 –º–∏–Ω—É—Ç –¥–ª—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏

    def __init__(self, session: AsyncSession):
        self.session = session
        self.query_optimizer = QueryOptimizer(session)
        self.batch_processor = BatchProcessor(session, batch_size=self.DEFAULT_BATCH_SIZE)
        self.cache = CacheService(session)
        self.cache_ttl = self.DEFAULT_CACHE_TTL
        # –°–ø–∏—Å–æ–∫ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —Ñ–æ–Ω–æ–≤—ã—Ö –∑–∞–¥–∞—á
        self.background_tasks = []


    async def track_feature_usage(
            self,
            user_id: int,
            feature_type: str,
            content_type: Optional[str] = None,  # Changed from ContentType to str
            success: bool = True,
            usage_data: Dict = None,
            error_type: Optional[str] = None,
            generation_time: Optional[float] = None,
            tokens_used: Optional[int] = None
    ) -> None:
        """Track feature usage with optimized batch processing"""
        try:
            # Convert string content_type to ContentType enum if needed
            content_type_enum = None
            if content_type:
                try:
                    content_type_enum = ContentType(content_type)
                except (ValueError, TypeError) as e:
                    logger.warning(f"Invalid content_type: {content_type}. Error: {str(e)}")
                    # We'll keep the conversion error but continue with None

            # Create usage record
            usage_record = {
                'user_id': user_id,
                'feature_type': feature_type,
                'content_type': content_type_enum,  # Use converted enum or None
                'success': success,
                'usage_data': usage_data or {},
                'error_type': error_type,
                'created_at': datetime.utcnow()
            }

            # –°–æ–∑–¥–∞–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—É—é –∑–∞–¥–∞—á—É –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø–∏—Å–∏ —Å –Ω–æ–≤–æ–π —Å–µ—Å—Å–∏–µ–π
            # –≠—Ç–æ –ø–æ–∑–≤–æ–ª–∏—Ç –Ω–µ –±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å –æ—Å–Ω–æ–≤–Ω–æ–π –ø–æ—Ç–æ–∫ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∏ –∏–∑–±–µ–∂–∞—Ç—å –ø—Ä–æ–±–ª–µ–º —Å —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—è–º–∏
            task = asyncio.create_task(
                self._process_usage_record_with_new_session(usage_record)
            )
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–¥–∞—á—É –≤ —Å–ø–∏—Å–æ–∫ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è
            self.background_tasks.append(task)
            
            # –û—á–∏—â–∞–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã–µ –∑–∞–¥–∞—á–∏
            self.background_tasks = [t for t in self.background_tasks if not t.done()]
                
            # If generation metrics provided, track them separately
            if content_type and generation_time and tokens_used is not None:
                # –°–æ–∑–¥–∞–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—É—é –∑–∞–¥–∞—á—É –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫ —Å –Ω–æ–≤–æ–π —Å–µ—Å—Å–∏–µ–π
                metrics_task = asyncio.create_task(
                    self._save_generation_metrics_with_new_session(
                        user_id,
                        content_type_enum,
                        generation_time,
                        tokens_used,
                        success
                    )
                )
                
                # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–¥–∞—á—É –≤ —Å–ø–∏—Å–æ–∫ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è
                self.background_tasks.append(metrics_task)
                
                # –û—á–∏—â–∞–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã–µ –∑–∞–¥–∞—á–∏
                self.background_tasks = [t for t in self.background_tasks if not t.done()]
                
        except Exception as e:
            logger.error(f"Error tracking feature usage: {str(e)}")
            # –ù–µ –ø–æ–¥–Ω–∏–º–∞–µ–º –∏—Å–∫–ª—é—á–µ–Ω–∏–µ, —á—Ç–æ–±—ã –Ω–µ –ø—Ä–µ—Ä—ã–≤–∞—Ç—å –æ—Å–Ω–æ–≤–Ω–æ–π –ø–æ—Ç–æ–∫

    async def _process_usage_record(self, usage_record: Dict) -> None:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–π –∑–∞–ø–∏—Å–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ñ—É–Ω–∫—Ü–∏–∏"""
        try:
            # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç FeatureUsage
            feature_usage = FeatureUsage(**usage_record)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–ø–∏—Å—å –≤ —Å–µ—Å—Å–∏—é
            self.session.add(feature_usage)
            
            # –ö–æ–º–º–∏—Ç–∏–º –∏–∑–º–µ–Ω–µ–Ω–∏—è
            await self.session.commit()
            
            # –ò–Ω–≤–∞–ª–∏–¥–∏—Ä—É–µ–º –∫—ç—à –∞–Ω–∞–ª–∏—Ç–∏–∫–∏
            await self.cache.invalidate_pattern("feature_usage:*")
            
        except Exception as e:
            # –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –æ—Ç–∫–∞—Ç —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏
            try:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∞–∫—Ç–∏–≤–Ω–æ–π —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ —á–µ—Ä–µ–∑ _transaction
                if hasattr(self.session, '_transaction') and self.session._transaction:
                    await self.session.rollback()
            except Exception as rollback_error:
                # –ï—Å–ª–∏ –æ—Ç–∫–∞—Ç –Ω–µ —É–¥–∞–ª—Å—è, –ø—Ä–æ—Å—Ç–æ –ª–æ–≥–∏—Ä—É–µ–º –æ—à–∏–±–∫—É –∏ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º
                logger.error(f"Error during rollback: {str(rollback_error)}")
            
            logger.error(f"Error processing usage record: {str(e)}")

    async def _save_generation_metrics(
            self, 
            user_id: int, 
            content_type: ContentType, 
            generation_time: float, 
            tokens_used: int, 
            success: bool
    ) -> None:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏"""
        try:
            # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç –º–µ—Ç—Ä–∏–∫
            metrics = DetailedGenerationMetrics(
                user_id=user_id,
                content_type=content_type,
                generation_time=generation_time,
                tokens_used=tokens_used,
                success=success,
                created_at=datetime.utcnow()
            )
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–ø–∏—Å—å –≤ —Å–µ—Å—Å–∏—é
            self.session.add(metrics)
            
            # –ö–æ–º–º–∏—Ç–∏–º –∏–∑–º–µ–Ω–µ–Ω–∏—è
            await self.session.commit()
            
        except Exception as e:
            await self.session.rollback()
            logger.error(f"Error saving generation metrics: {str(e)}")

    async def get_feature_usage_analytics(
            self,
            period: str = 'week',
            feature_type: Optional[str] = None,
            content_type: Optional[str] = None
    ) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ñ—É–Ω–∫—Ü–∏–π —Å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –∑–∞–ø—Ä–æ—Å–∞–º–∏"""
        try:
            # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–ª—é—á –∫—ç—à–∞
            cache_key = f"feature_usage:{period}:{feature_type or 'all'}:{content_type or 'all'}"
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
            cached_data = await self.cache.get_cached_data(cache_key)
            if cached_data:
                return cached_data
                
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–µ—Ä–∏–æ–¥
            end_date = datetime.utcnow()
            start_date = self._get_start_date(end_date, period)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –º–∞—Ç–µ—Ä–∏–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–≥–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è
            # –ï—Å–ª–∏ –æ–Ω–æ –µ—Å—Ç—å, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤
            has_materialized_view = await self._check_materialized_view_exists('feature_usage_daily_summary')
            
            if has_materialized_view and period in ['week', 'month', 'year']:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–∞—Ç–µ—Ä–∏–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –¥–ª—è –±–æ–ª–µ–µ –±—ã—Å—Ç—Ä–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
                query = text("""
                    SELECT 
                        feature_type,
                        content_type,
                        SUM(total_count) as count,
                        SUM(unique_users) as unique_users,
                        AVG(success_rate) as success_rate
                    FROM 
                        feature_usage_daily_summary
                    WHERE 
                        day >= :start_date
                """)
                
                params = {"start_date": start_date}
                
                if feature_type:
                    query = text(f"{query.text} AND feature_type = :feature_type")
                    params["feature_type"] = feature_type
                    
                if content_type:
                    query = text(f"{query.text} AND content_type = :content_type")
                    params["content_type"] = content_type
                    
                query = text(f"{query.text} GROUP BY feature_type, content_type ORDER BY count DESC")
                
                result = await self.session.execute(query, params)
                rows = result.fetchall()
            else:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—ã—á–Ω—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                query = select([
                    FeatureUsage.feature_type,
                    FeatureUsage.content_type,
                    func.count().label('count'),
                    func.count(func.distinct(FeatureUsage.user_id)).label('unique_users'),
                    func.avg(func.case(
                        [(FeatureUsage.success == True, 1)],
                        else_=0
                    )).label('success_rate')
                ]).where(
                    FeatureUsage.created_at.between(start_date, end_date)
                )
                
                if feature_type:
                    query = query.where(FeatureUsage.feature_type == feature_type)
                if content_type:
                    query = query.where(FeatureUsage.content_type == content_type)
                    
                query = query.group_by(
                    FeatureUsage.feature_type,
                    FeatureUsage.content_type
                ).order_by(
                    func.count().desc()
                )
                
                result = await self.session.execute(query)
                rows = result.fetchall()
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            analytics_data = {
                'period': period,
                'start_date': start_date.isoformat(),
                'end_date': end_date.isoformat(),
                'features': []
            }
            
            total_count = 0
            unique_users_set = set()
            
            for row in rows:
                feature_data = {
                    'feature_type': row.feature_type,
                    'content_type': row.content_type,
                    'count': row.count,
                    'unique_users': row.unique_users,
                    'success_rate': float(row.success_rate) if row.success_rate is not None else 0.0
                }
                analytics_data['features'].append(feature_data)
                total_count += row.count
                
                # –î–ª—è —Ç–æ—á–Ω–æ–≥–æ –ø–æ–¥—Å—á–µ—Ç–∞ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –Ω–∞–º –Ω—É–∂–Ω—ã –∏—Ö ID
                # –ù–æ –≤ –º–∞—Ç–µ—Ä–∏–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–º –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–∏ —É –Ω–∞—Å —Ç–æ–ª—å–∫–æ –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
                # –ü–æ—ç—Ç–æ–º—É –º—ã –ø—Ä–æ—Å—Ç–æ —Å—É–º–º–∏—Ä—É–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –ø–æ –∫–∞–∂–¥–æ–π —Ñ—É–Ω–∫—Ü–∏–∏
                # –≠—Ç–æ –¥–∞—Å—Ç –ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ, –Ω–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–µ –¥–ª—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏
                unique_users_set.add(row.unique_users)
            
            analytics_data['total_count'] = total_count
            analytics_data['unique_users'] = sum(unique_users_set)
            
            # –ö—ç—à–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            await self.cache.cache_data(
                cache_key,
                analytics_data,
                ttl=self.ANALYTICS_CACHE_TTL
            )
            
            return analytics_data
            
        except Exception as e:
            logger.error(f"Error getting feature usage analytics: {str(e)}")
            return {
                'period': period,
                'error': str(e),
                'features': []
            }

    async def _check_materialized_view_exists(self, view_name: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è –º–∞—Ç–µ—Ä–∏–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–≥–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è"""
        try:
            query = text("""
                SELECT EXISTS (
                    SELECT 1 
                    FROM pg_matviews 
                    WHERE matviewname = :view_name
                )
            """)
            
            result = await self.session.execute(query, {"view_name": view_name})
            return result.scalar() or False
        except Exception as e:
            logger.error(f"Error checking materialized view: {str(e)}")
            return False

    async def create_materialized_views(self) -> None:
        """–°–æ–∑–¥–∞–Ω–∏–µ –º–∞—Ç–µ—Ä–∏–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∑–∞–ø—Ä–æ—Å–æ–≤"""
        try:
            # –°–æ–∑–¥–∞–µ–º –º–∞—Ç–µ—Ä–∏–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –¥–ª—è –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            daily_stats_view = text("""
                CREATE MATERIALIZED VIEW IF NOT EXISTS feature_usage_daily_summary AS
                SELECT 
                    DATE_TRUNC('day', created_at) AS day,
                    feature_type,
                    content_type,
                    COUNT(*) AS total_count,
                    COUNT(DISTINCT user_id) AS unique_users,
                    AVG(CASE WHEN success THEN 1 ELSE 0 END) AS success_rate
                FROM 
                    feature_usage
                GROUP BY 
                    DATE_TRUNC('day', created_at),
                    feature_type,
                    content_type;
            """)
            
            await self.session.execute(daily_stats_view)
            
            # –°–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å –¥–ª—è –º–∞—Ç–µ—Ä–∏–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–≥–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –æ—Ç–¥–µ–ª—å–Ω—ã–º –∑–∞–ø—Ä–æ—Å–æ–º
            daily_stats_index = text("""
                CREATE INDEX IF NOT EXISTS idx_feature_usage_daily_summary_day 
                ON feature_usage_daily_summary(day);
            """)
            
            await self.session.execute(daily_stats_index)
            
            # –°–æ–∑–¥–∞–µ–º –º–∞—Ç–µ—Ä–∏–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
            user_stats_view = text("""
                CREATE MATERIALIZED VIEW IF NOT EXISTS user_activity_summary AS
                SELECT 
                    user_id,
                    COUNT(*) AS total_actions,
                    MIN(created_at) AS first_action,
                    MAX(created_at) AS last_action,
                    COUNT(DISTINCT DATE_TRUNC('day', created_at)) AS active_days
                FROM 
                    feature_usage
                GROUP BY 
                    user_id;
            """)
            
            await self.session.execute(user_stats_view)
            
            # –°–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å –¥–ª—è –º–∞—Ç–µ—Ä–∏–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–≥–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –æ—Ç–¥–µ–ª—å–Ω—ã–º –∑–∞–ø—Ä–æ—Å–æ–º
            user_stats_index = text("""
                CREATE INDEX IF NOT EXISTS idx_user_activity_summary_user_id 
                ON user_activity_summary(user_id);
            """)
            
            await self.session.execute(user_stats_index)
            
            # –ö–æ–º–º–∏—Ç–∏–º –∏–∑–º–µ–Ω–µ–Ω–∏—è
            await self.session.commit()
            
            logger.info("Created materialized views for analytics")
            
        except Exception as e:
            await self.session.rollback()
            logger.error(f"Error creating materialized views: {str(e)}")

    async def refresh_materialized_views(self) -> None:
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–∞—Ç–µ—Ä–∏–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π"""
        try:
            # –û–±–Ω–æ–≤–ª—è–µ–º –º–∞—Ç–µ—Ä–∏–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –¥–ª—è –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            refresh_daily_stats = text("""
                REFRESH MATERIALIZED VIEW feature_usage_daily_summary;
            """)
            
            await self.session.execute(refresh_daily_stats)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –º–∞—Ç–µ—Ä–∏–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
            refresh_user_stats = text("""
                REFRESH MATERIALIZED VIEW user_activity_summary;
            """)
            
            await self.session.execute(refresh_user_stats)
            
            # –ö–æ–º–º–∏—Ç–∏–º –∏–∑–º–µ–Ω–µ–Ω–∏—è
            await self.session.commit()
            
            logger.info("Refreshed materialized views for analytics")
            
        except Exception as e:
            await self.session.rollback()
            logger.error(f"Error refreshing materialized views: {str(e)}")

    async def cleanup_old_data(self) -> None:
        """–û—á–∏—Å—Ç–∫–∞ —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∞–Ω–∞–ª–∏—Ç–∏–∫–∏"""
        try:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–∞—Ç—É –¥–ª—è –æ—á–∏—Å—Ç–∫–∏
            cutoff_date = datetime.utcnow() - timedelta(days=self.DEFAULT_CLEANUP_DAYS)
            
            # –£–¥–∞–ª—è–µ–º —É—Å—Ç–∞—Ä–µ–≤—à–∏–µ –¥–∞–Ω–Ω—ã–µ
            delete_query = text("""
                DELETE FROM feature_usage
                WHERE created_at < :cutoff_date
            """)
            
            await self.session.execute(delete_query, {"cutoff_date": cutoff_date})
            
            # –£–¥–∞–ª—è–µ–º —É—Å—Ç–∞—Ä–µ–≤—à–∏–µ –º–µ—Ç—Ä–∏–∫–∏
            delete_metrics_query = text("""
                DELETE FROM detailed_generation_metrics
                WHERE date < :cutoff_date
            """)
            
            await self.session.execute(delete_metrics_query, {"cutoff_date": cutoff_date})
            
            # –ö–æ–º–º–∏—Ç–∏–º –∏–∑–º–µ–Ω–µ–Ω–∏—è
            await self.session.commit()
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –º–∞—Ç–µ—Ä–∏–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è
            await self.refresh_materialized_views()
            
            logger.info(f"Cleaned up analytics data older than {cutoff_date}")
            
        except Exception as e:
            await self.session.rollback()
            logger.error(f"Error cleaning up old analytics data: {str(e)}")

    def _get_start_date(self, end_date: datetime, period: str) -> datetime:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–∞—á–∞–ª—å–Ω–æ–π –¥–∞—Ç—ã –¥–ª—è –ø–µ—Ä–∏–æ–¥–∞"""
        if period == 'day':
            return end_date - timedelta(days=1)
        elif period == 'week':
            return end_date - timedelta(days=7)
        elif period == 'month':
            return end_date - timedelta(days=30)
        elif period == 'year':
            return end_date - timedelta(days=365)
        else:
            return end_date - timedelta(days=7)  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –Ω–µ–¥–µ–ª—è

    async def __aenter__(self):
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –≤—Å–µ—Ö —Ñ–æ–Ω–æ–≤—ã—Ö –∑–∞–¥–∞—á
        if self.background_tasks:
            await asyncio.gather(*self.background_tasks, return_exceptions=True)

    async def _process_usage_record_with_new_session(self, usage_record: Dict) -> None:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–π –∑–∞–ø–∏—Å–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ñ—É–Ω–∫—Ü–∏–∏ —Å –Ω–æ–≤–æ–π —Å–µ—Å—Å–∏–µ–π"""
        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é —Å–µ—Å—Å–∏—é –¥–ª—è –∏–∑–æ–ª—è—Ü–∏–∏ –æ—Ç –æ—Å–Ω–æ–≤–Ω–æ–π —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏
        async with async_session() as session:
            try:
                # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç FeatureUsage
                feature_usage = FeatureUsage(**usage_record)
                
                # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–ø–∏—Å—å –≤ —Å–µ—Å—Å–∏—é
                session.add(feature_usage)
                
                # –ö–æ–º–º–∏—Ç–∏–º –∏–∑–º–µ–Ω–µ–Ω–∏—è
                await session.commit()
                
                # –ò–Ω–≤–∞–ª–∏–¥–∏—Ä—É–µ–º –∫—ç—à –∞–Ω–∞–ª–∏—Ç–∏–∫–∏
                cache = CacheService(session)
                await cache.invalidate_pattern("feature_usage:*")
                
            except Exception as e:
                # –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –æ—Ç–∫–∞—Ç —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏
                try:
                    await session.rollback()
                except Exception as rollback_error:
                    logger.error(f"Error during rollback in new session: {str(rollback_error)}")
                
                logger.error(f"Error processing usage record with new session: {str(e)}")

    async def _save_generation_metrics_with_new_session(
            self, 
            user_id: int, 
            content_type: ContentType, 
            generation_time: float, 
            tokens_used: int, 
            success: bool
    ) -> None:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å –Ω–æ–≤–æ–π —Å–µ—Å—Å–∏–µ–π"""
        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é —Å–µ—Å—Å–∏—é –¥–ª—è –∏–∑–æ–ª—è—Ü–∏–∏ –æ—Ç –æ—Å–Ω–æ–≤–Ω–æ–π —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏
        async with async_session() as session:
            try:
                # –°–æ–∑–¥–∞–µ–º –∑–∞–ø–∏—Å—å –º–µ—Ç—Ä–∏–∫
                metrics = DetailedGenerationMetrics(
                    user_id=user_id,
                    content_type=content_type,
                    generation_time=generation_time,
                    tokens_used=tokens_used,
                    success=success,
                    date=datetime.utcnow().date()
                )
                
                # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–ø–∏—Å—å –≤ —Å–µ—Å—Å–∏—é
                session.add(metrics)
                
                # –ö–æ–º–º–∏—Ç–∏–º –∏–∑–º–µ–Ω–µ–Ω–∏—è
                await session.commit()
                
                # –ò–Ω–≤–∞–ª–∏–¥–∏—Ä—É–µ–º –∫—ç—à –∞–Ω–∞–ª–∏—Ç–∏–∫–∏
                cache = CacheService(session)
                await cache.invalidate_pattern("generation_metrics:*")
                
            except Exception as e:
                # –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –æ—Ç–∫–∞—Ç —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏
                try:
                    await session.rollback()
                except Exception as rollback_error:
                    logger.error(f"Error during rollback in new session: {str(rollback_error)}")
                
                logger.error(f"Error saving generation metrics with new session: {str(e)}")

class AchievementManager:
    # ... existing code ...
    
    async def get_available_achievements(self, user_id=None):
        """
        –ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–π
        
        Args:
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            
        Returns:
            List[Dict]: –°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–π
        """
        try:
            # –ë–∞–∑–æ–≤—ã–π —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–π
            achievements = [
                {
                    "id": "first_generation",
                    "code": "first_generation",
                    "name": "First Generation",
                    "description": "Create your first content",
                    "icon": "üéØ",
                    "conditions": {"generations_count": 1},
                    "points_reward": 10
                },
                {
                    "id": "power_user",
                    "code": "power_user",
                    "name": "Power User",
                    "description": "Create 10 generations",
                    "icon": "‚ö°",
                    "conditions": {"generations_count": 10},
                    "points_reward": 50
                },
                {
                    "id": "content_master",
                    "code": "content_master",
                    "name": "Content Master",
                    "description": "Create 50 generations",
                    "icon": "üèÜ",
                    "conditions": {"generations_count": 50},
                    "points_reward": 200
                }
            ]
            
            # –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å, –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–æ–≥—Ä–µ—Å—Å–µ
            if user_id:
                # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ª–æ–≥–∏–∫—É –ø–æ–ª—É—á–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
                pass
                
            return achievements
        except Exception as e:
            logger.error(f"Error getting available achievements: {str(e)}")
            return []